{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAVYANSHTYAGI/Ransomware-Analysis-using-Machine-Learning-and-Deep-Learning/blob/main/DL_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qO6JYp0PLfxr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau , LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfUBKu7EL3_6",
        "outputId": "e786577c-65a7-41c0-b970-d7d52352ce85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kGbyb2FcNvvd"
      },
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "data_path = '/content/drive/MyDrive/ransomware_analysis_files/gan_for_synthetic/balanced_oversampled_very_noisy_extended_5k.csv'\n",
        "dataset = pd.read_csv(data_path)\n",
        "\n",
        "# Check and remove NaN values in the target variable 'Tag_y'\n",
        "if dataset['Tag_y'].isnull().any():\n",
        "    print(\"NaN values found in target variable 'Tag_y', removing rows...\")\n",
        "    dataset = dataset.dropna(subset=['Tag_y'])\n",
        "\n",
        "X = dataset.drop(['Tag_y', 'Tag_x','filename', 'cryptographic_usage_encryption_algorithms','complexity_metrics_function_count', 'data_flow_collections_usage', 'hardcoded_urls', 'obfuscation_techniques_variable_name_length', 'unique_suspicious_strings'], axis=1)\n",
        "y = dataset['Tag_y']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "method 1"
      ],
      "metadata": {
        "id": "sQPHecOYzKiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3QZ3XKdLfxs"
      },
      "outputs": [],
      "source": [
        "# Normalize features to [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Reshape data into images\n",
        "num_features = X_scaled.shape[1]\n",
        "next_square = int(np.ceil(np.sqrt(num_features)))  # Calculate the next perfect square\n",
        "total_pixels = next_square**2\n",
        "padding_required = total_pixels - num_features\n",
        "\n",
        "# Pad the features to make the number a perfect square\n",
        "X_padded = np.pad(X_scaled, ((0, 0), (0, padding_required)), 'constant')\n",
        "X_images = X_padded.reshape(-1, next_square, next_square, 1)  # Reshape into (number of samples, height, width, channels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "method 2"
      ],
      "metadata": {
        "id": "yf0ETZl5zMKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Function to convert CSV to image array directly in memory\n",
        "def csv_to_image_array(data, dtype=None, img_dim=(224,224), img_type='RGB'):\n",
        "    images = []\n",
        "    no_of_features = data.shape[1]\n",
        "    sqrt_of_no_of_features = int(np.sqrt(no_of_features))\n",
        "    if np.sqrt(no_of_features) > sqrt_of_no_of_features:\n",
        "        sqrt_of_no_of_features += 1\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        pixels = np.resize(row.values, (sqrt_of_no_of_features**2)).reshape(sqrt_of_no_of_features, sqrt_of_no_of_features)\n",
        "        image = Image.fromarray(pixels.astype(np.uint8))\n",
        "        if img_type != 'Gray':\n",
        "            image = image.convert(img_type)\n",
        "        image = image.resize(img_dim, Image.Resampling.NEAREST)\n",
        "        images.append(np.array(image))\n",
        "    return np.array(images)\n",
        "\n",
        "# Load your dataset\n",
        "data_path = '/content/drive/MyDrive/ransomware_analysis_files/gan_for_synthetic/balanced_oversampled_very_noisy_extended_5k.csv'\n",
        "dataset = pd.read_csv(data_path)\n",
        "\n",
        "# Check for NaN values in the target variable and remove them if found\n",
        "if dataset['Tag_y'].isnull().any():\n",
        "    print(\"NaN values found in target variable 'Tag_y', removing rows...\")\n",
        "    dataset = dataset.dropna(subset=['Tag_y'])\n",
        "\n",
        "# Dropping unnecessary columns\n",
        "features_to_drop = ['Tag_y', 'Tag_x', 'filename', 'cryptographic_usage_encryption_algorithms',\n",
        "                    'complexity_metrics_function_count', 'data_flow_collections_usage', 'hardcoded_urls',\n",
        "                    'obfuscation_techniques_variable_name_length', 'unique_suspicious_strings']\n",
        "X_data = dataset.drop(columns=features_to_drop)\n",
        "y_train = dataset['Tag_y'].values  # Assuming y_train corresponds to the rows in the CSV\n",
        "\n",
        "# Convert the filtered CSV data into images\n",
        "X_train = csv_to_image_array(X_data, dtype='uint8', img_dim=(224,224), img_type='RGB')\n",
        "\n",
        "# Optionally, verify the shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "id": "sQzTC_9a8BRD",
        "outputId": "f134dcf4-5b29-4b27-c35d-f8ad18f8f0ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ea390ae9c461>:15: RuntimeWarning: invalid value encountered in cast\n",
            "  image = Image.fromarray(pixels.astype(np.uint8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (12012, 224, 224, 3)\n",
            "y_train shape: (12012,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pseudo_color_image(data, dtype=np.uint8, img_dim=(224, 224), default_value=0):\n",
        "    images = []\n",
        "    color_map = {\n",
        "        0: (0, 0, 0),  # Black for background\n",
        "        1: (255, 0, 0),  # Red\n",
        "        2: (0, 255, 0),  # Green\n",
        "        3: (0, 0, 255),  # Blue\n",
        "        # Define more as needed\n",
        "    }\n",
        "\n",
        "    data = data.fillna(default_value)  # Fill NaN values with a default value\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        # Process each pixel\n",
        "        colored_image = np.zeros((row.size * 3,), dtype=dtype)\n",
        "        for i, value in enumerate(row):\n",
        "            colored_image[i*3:i*3+3] = color_map.get(int(value), (255, 255, 255))\n",
        "\n",
        "        # Calculate the dimension needed for a square image\n",
        "        dim = int(np.ceil(np.sqrt(len(colored_image) / 3)))\n",
        "        full_size = dim * dim * 3\n",
        "        colored_image = np.pad(colored_image, (0, full_size - len(colored_image)), 'constant', constant_values=0)\n",
        "\n",
        "        # Reshape and resize\n",
        "        image = Image.fromarray(colored_image.reshape((dim, dim, 3)))\n",
        "        image = image.resize(img_dim, Image.Resampling.NEAREST)\n",
        "        images.append(np.array(image))\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Convert the filtered CSV data into pseudo-colored images\n",
        "X_train = pseudo_color_image(X_data)\n"
      ],
      "metadata": {
        "id": "Y1XTJdS0FIS1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_images_by_label(X_train, y_train):\n",
        "    unique_labels = np.unique(y_train)\n",
        "\n",
        "    for label in unique_labels:\n",
        "        indices = np.where(y_train == label)[0]\n",
        "\n",
        "        # User inputs the number of images they want to see for this label\n",
        "        num_images = int(input(f\"Enter the number of images you want to display for label {label}: \"))\n",
        "\n",
        "        if num_images > len(indices):\n",
        "            print(f\"Only {len(indices)} images available, showing all.\")\n",
        "            num_images = len(indices)\n",
        "\n",
        "        selected_indices = indices[:num_images]\n",
        "\n",
        "        # Determine the number of columns for subplot\n",
        "        cols = min(num_images, 5)  # Show a maximum of 5 images per row\n",
        "        rows = (num_images + cols - 1) // cols  # Calculate the needed rows\n",
        "\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
        "\n",
        "        if rows * cols > 1:\n",
        "            axes = axes.ravel()\n",
        "        else:\n",
        "            axes = [axes]\n",
        "\n",
        "        for ax, idx in zip(axes, selected_indices):\n",
        "            ax.imshow(X_train[idx])\n",
        "            ax.set_title(f'Index: {idx}', fontsize=8)\n",
        "            ax.axis('off')\n",
        "\n",
        "        for ax in axes[len(selected_indices):]:\n",
        "            ax.axis('off')  # Hide unused subplots\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "# X_train = np.random.rand(100, 64, 64, 3)  # Example array of 100 64x64 RGB images\n",
        "# y_train = np.random.randint(0, 2, 100)    # Example array of 100 labels (0 or 1)\n",
        "show_images_by_label(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "54Y_hVsP8yl7",
        "outputId": "3f1b6d04-6af0-4642-c5bf-de3724f75b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number of images you want to display for label 0: 8\n",
            "Enter the number of images you want to display for label 1: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = None\n",
        "X_test = None\n"
      ],
      "metadata": {
        "id": "MWlM9BCRuwtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = None\n",
        "y_test = None"
      ],
      "metadata": {
        "id": "Pl5YLdUR1V0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Function to resize images to a new size using TensorFlow\n",
        "def resize_images(images, new_size=(224, 224)):\n",
        "    # Ensure images are a tensor before resizing\n",
        "    images_tensor = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "    return tf.image.resize(images_tensor, new_size)\n",
        "\n",
        "# Resize X_train to (224, 224)\n",
        "X_train = resize_images(X_train)\n",
        "\n",
        "# Convert y_train to categorical\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "# Print shapes to verify everything is as expected\n",
        "print(\"Resized X_train shape:\", X_train.shape)\n",
        "print(\"Categorical y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "id": "ziJVsApFGY9R",
        "outputId": "2c1ce9b1-5655-47a2-e10c-03a9d33f6cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized X_train shape: (12012, 224, 224, 3)\n",
            "Categorical y_train shape: (12012, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "method"
      ],
      "metadata": {
        "id": "YcoqYG2dJlSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dIVoMKstltk7",
        "outputId": "a522544f-fb7d-4903-b8e5-2f2e30df190b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (9609, 224, 224, 3)\n",
            "X_val shape: (1201, 224, 224, 3)\n",
            "X_test shape: (1202, 224, 224, 3)\n",
            "y_train shape: (9609, 2)\n",
            "y_val shape: (1201, 2)\n",
            "y_test shape: (1202, 2)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(X, y, train_size, val_size, test_size):\n",
        "    # Convert TensorFlow tensors to numpy arrays if they are not already\n",
        "    if isinstance(X, tf.Tensor):\n",
        "        X = X.numpy()\n",
        "    if isinstance(y, tf.Tensor):\n",
        "        y = y.numpy()\n",
        "\n",
        "    # First split to separate out the training set\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_size, random_state=42)\n",
        "\n",
        "    # Calculate the proportion of the remaining data to allocate to validation\n",
        "    # This calculation ensures that the validation and test sets are of the correct relative size\n",
        "    prop_remain = val_size / (val_size + test_size)\n",
        "\n",
        "    # Second split to separate out the validation and test sets\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size=prop_remain, random_state=42)\n",
        "\n",
        "    # Convert arrays back to tensors if necessary\n",
        "    X_train, X_val, X_test = map(tf.convert_to_tensor, [X_train, X_val, X_test])\n",
        "    y_train, y_val, y_test = map(tf.convert_to_tensor, [y_train, y_val, y_test])\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Assuming X_train_resized and y_train_categorical are ready and correctly formatted as tensors\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_train, y_train, 0.8, 0.1, 0.1)\n",
        "\n",
        "# Print the shapes of the datasets to verify the splits\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "method 2"
      ],
      "metadata": {
        "id": "kBVFqAL_Jpqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(X, y, train_size, val_size, test_size):\n",
        "    # Keep data handling on the CPU\n",
        "    with tf.device('/cpu:0'):\n",
        "        # Convert TensorFlow tensors to numpy arrays if they are not already\n",
        "        if isinstance(X, tf.Tensor):\n",
        "            X = X.numpy()\n",
        "        if isinstance(y, tf.Tensor):\n",
        "            y = y.numpy()\n",
        "\n",
        "        # First split to separate out the training set\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_size, random_state=42)\n",
        "\n",
        "        # Calculate the proportion of the remaining data to allocate to validation\n",
        "        prop_remain = val_size / (val_size + test_size)\n",
        "\n",
        "        # Second split to separate out the validation and test sets\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size=prop_remain, random_state=42)\n",
        "\n",
        "        # Optionally convert arrays back to tensors here, if you plan on using them directly after this\n",
        "        # However, you can defer this conversion until you are about to use them in a model to save memory\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Assuming X_train_resized and y_train_categorical are ready and correctly formatted as tensors\n",
        "# This function now returns numpy arrays instead of tensors to prevent memory allocation on GPU\n",
        "X_train_np, X_val_np, X_test_np, y_train_np, y_val_np, y_test_np = split_data(X_train, y_train, 0.8, 0.1, 0.1)\n",
        "\n",
        "# Print the shapes of the datasets to verify the splits\n",
        "print(\"X_train shape:\", X_train_np.shape)\n",
        "print(\"X_val shape:\", X_val_np.shape)\n",
        "print(\"X_test shape:\", X_test_np.shape)\n",
        "print(\"y_train shape:\", y_train_np.shape)\n",
        "print(\"y_val shape:\", y_val_np.shape)\n",
        "print(\"y_test shape:\", y_test_np.shape)\n"
      ],
      "metadata": {
        "id": "9TAnHJ0LJnpT",
        "outputId": "b5293165-428c-4733-c80f-c7ecc3a051c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (7687, 224, 224, 3)\n",
            "X_val shape: (961, 224, 224, 3)\n",
            "X_test shape: (961, 224, 224, 3)\n",
            "y_train shape: (7687, 2)\n",
            "y_val shape: (961, 2)\n",
            "y_test shape: (961, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming y_train, y_val, and y_test are loaded as one-hot encoded arrays\n",
        "# Example conversion of a one-hot encoded label tensor to sparse labels\n",
        "y_train = tf.argmax(y_train, axis=1)\n",
        "y_val = tf.argmax(y_val, axis=1)\n",
        "y_test = tf.argmax(y_test, axis=1)\n"
      ],
      "metadata": {
        "id": "4EAOSh-EWtAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2FJiONFpLfxs"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation configuration\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=70,        # Random rotation between -10 to +10 degrees\n",
        "    width_shift_range=0.1,    # Horizontal shift\n",
        "    height_shift_range=0.1,   # Vertical shift\n",
        "    zoom_range=0.1,           # Random zoom\n",
        "    horizontal_flip=True,     # Horizontal flip\n",
        "    fill_mode='nearest'  ,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow(X_train_np, y_train_np, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom layers"
      ],
      "metadata": {
        "id": "WKADNdtdHgkp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhINMXs8Lfxt"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(next_square, next_square, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_categorical.shape[1], activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model with data augmentation\n",
        "model.fit(datagen.flow(X_train_resized, y_train, batch_size=64),\n",
        "          epochs=30,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUSTOM MODEL INSPIRED BY INCEPTIONV3"
      ],
      "metadata": {
        "id": "_xI_si5tT8Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input shape is the size of the images you are inputting\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "# Stem block\n",
        "model.add(Conv2D(32, (3,3), strides=(2,2), padding='valid', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(32, (3,3), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((3,3), strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(80, (1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(192, (3,3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D((3,3), strides=(2,2)))\n",
        "\n",
        "# Assuming adding one inception block (as a linear approximation)\n",
        "# Inception blocks here are simplified and not parallel\n",
        "model.add(Conv2D(64, (1,1), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((3,3), strides=(2,2), padding='same'))\n",
        "\n",
        "# It's not possible to implement cross-channel parameterized pooling (like in Inception modules) in a Sequential model directly\n",
        "\n",
        "# Final classifier\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='sigmoid'))  # Output layer size should match the number of classes\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Setup callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-6)\n",
        "model_checkpoint = ModelCheckpoint('best_hybrid_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "OTQBUNbIUAJj",
        "outputId": "5c89a57e-2245-43ba-cf92-e805d19cf9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m80\u001b[0m)          │           \u001b[38;5;34m5,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │         \u001b[38;5;34m138,432\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m102,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │          \u001b[38;5;34m66,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │           \u001b[38;5;34m2,050\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">138,432</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m392,626\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,626</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m392,626\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,626</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m80\u001b[0m)          │           \u001b[38;5;34m5,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │         \u001b[38;5;34m138,432\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m12,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m102,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │          \u001b[38;5;34m66,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │           \u001b[38;5;34m2,050\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">138,432</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m392,626\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,626</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m392,626\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,626</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single Pre-trained models"
      ],
      "metadata": {
        "id": "qPYClKZxHfjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6_8ZI9VLfxt",
        "outputId": "e8d67b32-80c2-4fff-f16c-07f447953b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "# Using MobileNetV2 as the base model with pre-trained ImageNet weights\n",
        "base_model = InceptionResNetV2(include_top=False,\n",
        "                         weights='imagenet',\n",
        "                         input_shape=(224, 224, 3))\n",
        "\n",
        "# Setting the base model as non-trainable\n",
        "base_model.trainable = True\n",
        "\n",
        "# Building the complete model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Configuring the optimizer\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "# Compiling the model with necessary parameters\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',  # This is important for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Setting up callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-6)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# The model is now ready to be trained with model.fit(), ensuring to provide validation data and using the callbacks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Model"
      ],
      "metadata": {
        "id": "Ed_pTpyvHsns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, VGG19\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Metric\n",
        "\n",
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "# Input shape\n",
        "input_shape = (224, 224, 3)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Load ResNet50 and VGG19 pre-trained models\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "vgg_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Set base models as trainable (or freeze as required)\n",
        "resnet_base.trainable = True\n",
        "vgg_base.trainable = True\n",
        "\n",
        "# Extract features\n",
        "resnet_features = GlobalAveragePooling2D()(resnet_base(inputs))\n",
        "vgg_features = GlobalAveragePooling2D()(vgg_base(inputs))\n",
        "\n",
        "# Concatenate features\n",
        "combined_features = Concatenate()([resnet_features, vgg_features])\n",
        "\n",
        "# Add a classification head\n",
        "x = Dense(512, activation='relu')(combined_features)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "# Build the model\n",
        "hybrid_model = Model(inputs, outputs)\n",
        "\n",
        "# Configure the optimizer\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "hybrid_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',  # Change to 'categorical_crossentropy' if using categorical targets\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        F1Score()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Setup callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "model_checkpoint = ModelCheckpoint('best_hybrid_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Model summary\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "id": "VQMgi_zqH9Ah",
        "outputId": "cbd2cb04-6eb5-40b3-af62-fcd47dbd4389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m20,024,384\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ vgg19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │      \u001b[38;5;34m1,311,232\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,448\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m130\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ vgg19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,071,234\u001b[0m (171.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,071,234</span> (171.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,018,114\u001b[0m (171.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,018,114</span> (171.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrw9Qz_VLfxu",
        "outputId": "05602f17-e955-4262-ecdc-47199468078a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (9609, 224, 224, 3)\n",
            "Shape of X_test: (721, 224, 224, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:1273: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 224, 224, 3) (64, 2)\n",
            "Batch X size: (64, 224, 224, 3) Batch y size: (64, 2)\n",
            "Validation X size: (1682, 224, 224, 3) Validation y size: (1682, 2)\n",
            "test X size: (721, 224, 224, 3) test y size: (721, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "for X_batch, y_batch in train_generator:\n",
        "    print(X_batch.shape, y_batch.shape)\n",
        "    break  # Just run one iteration to check\n",
        "\n",
        "for X_batch, y_batch in train_generator:\n",
        "    print('Batch X size:', X_batch.shape, 'Batch y size:', y_batch.shape)\n",
        "    if X_batch.shape[0] != y_batch.shape[0]:\n",
        "        print('Mismatch found')\n",
        "    break  # Stop after the first batch to check\n",
        "\n",
        "print('Validation X size:', X_val.shape, 'Validation y size:', y_val.shape)\n",
        "print('test X size:', X_test.shape, 'test y size:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BS7HAC_mLfxu",
        "outputId": "bc7394cd-61fb-4376-dcf5-7086ca16fdc8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4cb3b94993f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "history = hybrid_model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=(X_val_np, y_val_np),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
        "    shuffle=True)\n",
        "\n",
        "# Plotting training and validation loss and accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_val_np, y_val_np)\n",
        "print(f'val Loss: {loss}, val Accuracy: {accuracy}')\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_np, y_test_np)\n",
        "print(f'test Loss: {loss}, test Accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Assuming you have trained your model and have the validation and test datasets ready\n",
        "# Convert validation and test sets to tensors if not already done\n",
        "X_val, y_val = map(tf.convert_to_tensor, (X_val_np, y_val_np))\n",
        "X_test, y_test = map(tf.convert_to_tensor, (X_test_np, y_test_np))\n",
        "\n",
        "# Predictions\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_val_pred = np.argmax(y_val_pred, axis=1)\n",
        "y_val_true = np.argmax(y_val.numpy(), axis=1)\n",
        "\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
        "y_test_true = np.argmax(y_test.numpy(), axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_val = confusion_matrix(y_val_true, y_val_pred)\n",
        "cm_test = confusion_matrix(y_test_true, y_test_pred)\n",
        "\n",
        "# Classification Report\n",
        "cr_val = classification_report(y_val_true, y_val_pred)\n",
        "cr_test = classification_report(y_test_true, y_test_pred)\n",
        "\n",
        "print(\"Validation Confusion Matrix:\\n\", cm_val)\n",
        "print(\"Validation Classification Report:\\n\", cr_val)\n",
        "print(\"Test Confusion Matrix:\\n\", cm_test)\n",
        "print(\"Test Classification Report:\\n\", cr_test)\n",
        "\n",
        "# Plot confusion matrix (optional)\n",
        "fig, ax = plt.subplots()\n",
        "img = ax.imshow(cm_val, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.figure.colorbar(img, ax=ax)\n",
        "ax.set(title='Confusion Matrix Validation',\n",
        "       ylabel='True label',\n",
        "       xlabel='Predicted label')\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "thresh = cm_val.max() / 2.\n",
        "for i in range(cm_val.shape[0]):\n",
        "    for j in range(cm_val.shape[1]):\n",
        "        ax.text(j, i, format(cm_val[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm_val[i, j] > thresh else \"black\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I2j1A228KqQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vision transformer\n"
      ],
      "metadata": {
        "id": "c0bm-5aJZOTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the input images are already resized to 224x224 and normalized as needed\n",
        "input_shape = (224, 224, 3)  # Input shape expected by the ViT model\n",
        "\n",
        "\n",
        "# Convert NumPy arrays to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "# Batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Shuffle, batch, and prefetch the datasets\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "eAEAfXIdZN9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of the batches in the training dataset\n",
        "for X_batch, y_batch in train_dataset.take(1):  # Take a single batch\n",
        "    print(\"Train dataset - X_batch shape:\", X_batch.shape)\n",
        "    print(\"Train dataset - y_batch shape:\", y_batch.shape)\n",
        "\n",
        "# Check the shapes of the batches in the validation dataset\n",
        "#for X_batch, y_batch in val_dataset.take(1):  # Take a single batch\n",
        "#    print(\"Validation dataset - X_batch shape:\", X_batch.shape)\n",
        "#    print(\"Validation dataset - y_batch shape:\", y_batch.shape)\n",
        "\n",
        "# Check the shapes of the batches in the test dataset\n",
        "for X_batch, y_batch in test_dataset.take(1):  # Take a single batch\n",
        "    print(\"Test dataset - X_batch shape:\", X_batch.shape)\n",
        "    print(\"Test dataset - y_batch shape:\", y_batch.shape)"
      ],
      "metadata": {
        "id": "Axi1hV83ZVur",
        "outputId": "79133888-89bd-461d-e0cf-2494cc4464f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset - X_batch shape: (128, 224, 224, 3)\n",
            "Train dataset - y_batch shape: (128, 2)\n",
            "Test dataset - X_batch shape: (128, 224, 224, 3)\n",
            "Test dataset - y_batch shape: (128, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_hub\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "J9cpC5LLal4b",
        "outputId": "a0fa6531-e586-4a19-fa3e-31db258a51b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (4.25.5)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ViT model\n",
        "# Using the ViT model with 16x16 patches, pre-trained on ImageNet-21k and fine-tuned on ImageNet-1k\n",
        "vit_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
        "vit_layer = hub.KerasLayer(vit_url, trainable=True)"
      ],
      "metadata": {
        "id": "vtcbHlC5ZVsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "# Updated model function to correctly pass input tensors\n",
        "def build_finetune_vit_model(x, num_classes):\n",
        "    # Define the input layer with the correct shape and dtype\n",
        "    inputs = layers.Input(shape=x , dtype=tf.float32)\n",
        "\n",
        "    vit_layer = hub.KerasLayer(vit_url, trainable=True)\n",
        "\n",
        "    # Pass through the pre-trained Vision Transformer layer from TensorFlow Hub\n",
        "    vit_features = layers.Lambda(lambda x: vit_layer(x))(inputs)\n",
        "\n",
        "    # Add additional layers for classification\n",
        "    x = layers.Dense(512, activation='relu')(vit_features)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "input_shape = (224,224,3)\n",
        "# Build and compile the model\n",
        "\n",
        "finetune_vit_model = build_finetune_vit_model(input_shape, num_classes)\n",
        "\n",
        "\n",
        "finetune_vit_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Print model summary"
      ],
      "metadata": {
        "id": "vFXXMAYfZVpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_vit_model.summary()"
      ],
      "metadata": {
        "id": "WH0Bxh2dZVmy",
        "outputId": "cd484387-992f-4bb7-ffc3-a214b117522c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m393,728\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m514\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m525,570\u001b[0m (2.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">525,570</span> (2.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m525,570\u001b[0m (2.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">525,570</span> (2.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "\n",
        "# Fine-tune the model using the TensorFlow datasets\n",
        "history = finetune_vit_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=80,  # Fine-tune for a few more epochs\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = finetune_vit_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "sMaUk9O2bBS0",
        "outputId": "e4ec2ff3-f162-47a4-b7ec-765605a58a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 604ms/step - accuracy: 0.6247 - loss: 0.7773 - val_accuracy: 0.8451 - val_loss: 0.3738 - learning_rate: 1.0000e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8053 - loss: 0.4347 - val_accuracy: 0.8643 - val_loss: 0.3348 - learning_rate: 1.0000e-04\n",
            "Epoch 3/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8421 - loss: 0.3724 - val_accuracy: 0.8609 - val_loss: 0.3238 - learning_rate: 1.0000e-04\n",
            "Epoch 4/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8566 - loss: 0.3327 - val_accuracy: 0.8851 - val_loss: 0.2784 - learning_rate: 1.0000e-04\n",
            "Epoch 5/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8737 - loss: 0.3054 - val_accuracy: 0.8901 - val_loss: 0.2636 - learning_rate: 1.0000e-04\n",
            "Epoch 6/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8851 - loss: 0.2823 - val_accuracy: 0.9026 - val_loss: 0.2474 - learning_rate: 1.0000e-04\n",
            "Epoch 7/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8927 - loss: 0.2597 - val_accuracy: 0.8893 - val_loss: 0.2569 - learning_rate: 1.0000e-04\n",
            "Epoch 8/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8980 - loss: 0.2503 - val_accuracy: 0.9126 - val_loss: 0.2203 - learning_rate: 1.0000e-04\n",
            "Epoch 9/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9089 - loss: 0.2296 - val_accuracy: 0.9201 - val_loss: 0.2108 - learning_rate: 1.0000e-04\n",
            "Epoch 10/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9069 - loss: 0.2254 - val_accuracy: 0.9176 - val_loss: 0.1981 - learning_rate: 1.0000e-04\n",
            "Epoch 11/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9168 - loss: 0.2169 - val_accuracy: 0.9209 - val_loss: 0.1922 - learning_rate: 1.0000e-04\n",
            "Epoch 12/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9244 - loss: 0.1986 - val_accuracy: 0.9292 - val_loss: 0.1857 - learning_rate: 1.0000e-04\n",
            "Epoch 13/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9249 - loss: 0.1951 - val_accuracy: 0.9326 - val_loss: 0.1773 - learning_rate: 1.0000e-04\n",
            "Epoch 14/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9299 - loss: 0.1852 - val_accuracy: 0.9192 - val_loss: 0.1815 - learning_rate: 1.0000e-04\n",
            "Epoch 15/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9321 - loss: 0.1780 - val_accuracy: 0.9342 - val_loss: 0.1679 - learning_rate: 1.0000e-04\n",
            "Epoch 16/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9340 - loss: 0.1750 - val_accuracy: 0.9351 - val_loss: 0.1634 - learning_rate: 1.0000e-04\n",
            "Epoch 17/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9382 - loss: 0.1708 - val_accuracy: 0.9392 - val_loss: 0.1575 - learning_rate: 1.0000e-04\n",
            "Epoch 18/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9370 - loss: 0.1630 - val_accuracy: 0.9392 - val_loss: 0.1529 - learning_rate: 1.0000e-04\n",
            "Epoch 19/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9439 - loss: 0.1556 - val_accuracy: 0.9409 - val_loss: 0.1613 - learning_rate: 1.0000e-04\n",
            "Epoch 20/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9452 - loss: 0.1590 - val_accuracy: 0.9409 - val_loss: 0.1507 - learning_rate: 1.0000e-04\n",
            "Epoch 21/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9397 - loss: 0.1564 - val_accuracy: 0.9459 - val_loss: 0.1457 - learning_rate: 1.0000e-04\n",
            "Epoch 22/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9451 - loss: 0.1424 - val_accuracy: 0.9492 - val_loss: 0.1357 - learning_rate: 1.0000e-04\n",
            "Epoch 23/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9490 - loss: 0.1417 - val_accuracy: 0.9450 - val_loss: 0.1340 - learning_rate: 1.0000e-04\n",
            "Epoch 24/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9439 - loss: 0.1493 - val_accuracy: 0.9467 - val_loss: 0.1339 - learning_rate: 1.0000e-04\n",
            "Epoch 25/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9471 - loss: 0.1368 - val_accuracy: 0.9484 - val_loss: 0.1325 - learning_rate: 1.0000e-04\n",
            "Epoch 26/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9564 - loss: 0.1217 - val_accuracy: 0.9525 - val_loss: 0.1280 - learning_rate: 1.0000e-04\n",
            "Epoch 27/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.9536 - loss: 0.1272 - val_accuracy: 0.9359 - val_loss: 0.1548 - learning_rate: 1.0000e-04\n",
            "Epoch 28/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9509 - loss: 0.1274 - val_accuracy: 0.9509 - val_loss: 0.1274 - learning_rate: 1.0000e-04\n",
            "Epoch 29/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9541 - loss: 0.1253 - val_accuracy: 0.9550 - val_loss: 0.1215 - learning_rate: 1.0000e-04\n",
            "Epoch 30/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9550 - loss: 0.1274 - val_accuracy: 0.9425 - val_loss: 0.1436 - learning_rate: 1.0000e-04\n",
            "Epoch 31/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9520 - loss: 0.1241 - val_accuracy: 0.9509 - val_loss: 0.1184 - learning_rate: 1.0000e-04\n",
            "Epoch 32/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9593 - loss: 0.1102 - val_accuracy: 0.9509 - val_loss: 0.1325 - learning_rate: 1.0000e-04\n",
            "Epoch 33/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9573 - loss: 0.1089 - val_accuracy: 0.9550 - val_loss: 0.1126 - learning_rate: 1.0000e-04\n",
            "Epoch 34/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9609 - loss: 0.1060 - val_accuracy: 0.9525 - val_loss: 0.1144 - learning_rate: 1.0000e-04\n",
            "Epoch 35/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9619 - loss: 0.1033 - val_accuracy: 0.9575 - val_loss: 0.1100 - learning_rate: 1.0000e-04\n",
            "Epoch 36/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9598 - loss: 0.1074 - val_accuracy: 0.9525 - val_loss: 0.1160 - learning_rate: 1.0000e-04\n",
            "Epoch 37/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9635 - loss: 0.1031 - val_accuracy: 0.9584 - val_loss: 0.1108 - learning_rate: 1.0000e-04\n",
            "Epoch 38/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9622 - loss: 0.0961 - val_accuracy: 0.9567 - val_loss: 0.1093 - learning_rate: 1.0000e-04\n",
            "Epoch 39/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9638 - loss: 0.0944 - val_accuracy: 0.9584 - val_loss: 0.1052 - learning_rate: 1.0000e-04\n",
            "Epoch 40/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9612 - loss: 0.0989 - val_accuracy: 0.9609 - val_loss: 0.1004 - learning_rate: 1.0000e-04\n",
            "Epoch 41/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9656 - loss: 0.0914 - val_accuracy: 0.9559 - val_loss: 0.1088 - learning_rate: 1.0000e-04\n",
            "Epoch 42/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9687 - loss: 0.0856 - val_accuracy: 0.9559 - val_loss: 0.1058 - learning_rate: 1.0000e-04\n",
            "Epoch 43/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9626 - loss: 0.0957 - val_accuracy: 0.9592 - val_loss: 0.1100 - learning_rate: 1.0000e-04\n",
            "Epoch 44/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9697 - loss: 0.0827 - val_accuracy: 0.9600 - val_loss: 0.1001 - learning_rate: 2.0000e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9726 - loss: 0.0764 - val_accuracy: 0.9617 - val_loss: 0.0986 - learning_rate: 2.0000e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9739 - loss: 0.0720 - val_accuracy: 0.9642 - val_loss: 0.0989 - learning_rate: 2.0000e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9721 - loss: 0.0716 - val_accuracy: 0.9634 - val_loss: 0.0983 - learning_rate: 2.0000e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.9747 - loss: 0.0708 - val_accuracy: 0.9634 - val_loss: 0.1001 - learning_rate: 2.0000e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9764 - loss: 0.0685 - val_accuracy: 0.9609 - val_loss: 0.0981 - learning_rate: 2.0000e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9713 - loss: 0.0701 - val_accuracy: 0.9609 - val_loss: 0.1000 - learning_rate: 2.0000e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9778 - loss: 0.0655 - val_accuracy: 0.9609 - val_loss: 0.1034 - learning_rate: 2.0000e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9756 - loss: 0.0671 - val_accuracy: 0.9642 - val_loss: 0.0993 - learning_rate: 2.0000e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9786 - loss: 0.0611 - val_accuracy: 0.9650 - val_loss: 0.0996 - learning_rate: 4.0000e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9807 - loss: 0.0593 - val_accuracy: 0.9650 - val_loss: 0.0995 - learning_rate: 4.0000e-06\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9662 - loss: 0.0989\n",
            "Test accuracy: 0.9633943438529968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hybrid model including vision transformer"
      ],
      "metadata": {
        "id": "b4kgp1UHbtUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV3Small, InceptionV3\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Pre-trained ViT Model URL\n",
        "vit_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
        "# EfficientNetB5\n",
        "efficientnet_base = MobileNetV3Small(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
        "efficientnet_base.trainable = False  # Freezing EfficientNetB5 layers\n",
        "\n",
        "    # ResNet101\n",
        "resnet_base = InceptionV3(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
        "resnet_base.trainable = False  # Freezing ResNet101 layers\n",
        "\n",
        "# Build the Hybrid Model\n",
        "def build_heavy_hybrid_model(input_shape, num_classes):\n",
        "\n",
        "\n",
        "    # ViT (Vision Transformer)\n",
        "    vit_layer = hub.KerasLayer(vit_url, trainable=False, input_shape=input_shape)\n",
        "\n",
        "    # Input Layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Extract Features from EfficientNet and ResNet\n",
        "    efficientnet_features = efficientnet_base(inputs)\n",
        "    efficientnet_features = layers.GlobalAveragePooling2D()(efficientnet_features)\n",
        "\n",
        "    resnet_features = resnet_base(inputs)\n",
        "    resnet_features = layers.GlobalAveragePooling2D()(resnet_features)\n",
        "\n",
        "    # Concatenate EfficientNet and ResNet features\n",
        "    combined_features = layers.Concatenate()([efficientnet_features, resnet_features])\n",
        "\n",
        "    # Feed concatenated features into Vision Transformer\n",
        "    vit_features = layers.Lambda(lambda x: vit_layer(x))(inputs)\n",
        "\n",
        "\n",
        "    # Combine ViT features with EfficientNet + ResNet features\n",
        "    combined_features = layers.Concatenate()([combined_features, vit_features])\n",
        "\n",
        "    # Fully Connected Layers (deeper head for richer representations)\n",
        "    x = layers.Dense(512, activation='relu')(combined_features)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    # Output Layer (Softmax for classification)\n",
        "    outputs = layers.Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "    # Create and return the model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Compile the Heavy Hybrid Model\n",
        "input_shape = (224, 224, 3)\n",
        "heavy_hybrid_model = build_heavy_hybrid_model(input_shape=input_shape, num_classes=num_classes)\n",
        "heavy_hybrid_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "heavy_hybrid_model.summary()"
      ],
      "metadata": {
        "id": "bTEv6A-GbxB6",
        "outputId": "c8ea342d-0ad6-4adf-d1a6-70f34614e893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m4334752/4334752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ MobileNetV3Small          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)      │        \u001b[38;5;34m939,120\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m21,802,784\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ MobileNetV3Small[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ inception_v3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2624\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3392\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │      \u001b[38;5;34m1,737,216\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m514\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ MobileNetV3Small          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ MobileNetV3Small[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inception_v3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2624</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3392</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,737,216</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,610,962\u001b[0m (93.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,610,962</span> (93.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,869,058\u001b[0m (7.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,869,058</span> (7.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m22,741,904\u001b[0m (86.75 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,741,904</span> (86.75 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to gradually unfreeze layers of EfficientNet, ResNet, and ViT\n",
        "def gradual_unfreeze(model, base_model, layers_to_unfreeze):\n",
        "    base_model.trainable = True\n",
        "    # Unfreeze only the top layers (last 'layers_to_unfreeze' layers)\n",
        "    for layer in base_model.layers[:-layers_to_unfreeze]:\n",
        "        layer.trainable = False\n",
        "    return model\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Step 1: Train with frozen layers\n",
        "initial_epochs = 20\n",
        "history = heavy_hybrid_model.fit(train_dataset, validation_data=val_dataset, epochs=initial_epochs, callbacks=[early_stopping, reduce_lr, model_checkpoint])\n",
        "\n",
        "# Step 2: Unfreeze the top layers for fine-tuning\n",
        "layers_to_unfreeze = 50  # Modify this number based on your needs\n",
        "\n",
        "# Unfreeze top layers of EfficientNet, ResNet, and ViT\n",
        "heavy_hybrid_model = gradual_unfreeze(heavy_hybrid_model, efficientnet_base, layers_to_unfreeze)\n",
        "heavy_hybrid_model = gradual_unfreeze(heavy_hybrid_model, resnet_base, layers_to_unfreeze)\n",
        "vit_layer.trainable = True  # Fully unfreeze ViT\n",
        "\n",
        "# Step 3: Compile the model again with a lower learning rate for fine-tuning\n",
        "heavy_hybrid_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Continue training with unfrozen layers\n",
        "fine_tuning_epochs = 40\n",
        "history_finetune = heavy_hybrid_model.fit(train_dataset, validation_data=val_dataset,\n",
        "                                          epochs=fine_tuning_epochs, initial_epoch=initial_epochs,\n",
        "                                          callbacks=[early_stopping, reduce_lr, model_checkpoint])"
      ],
      "metadata": {
        "id": "_NyKjv0rby3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = heavy_hybrid_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "FkF5fOk6byzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwgQfdHsbyxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bio inspired"
      ],
      "metadata": {
        "id": "eYqZaZCkFJRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNetV3Small, InceptionV3\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# Custom generator for handling data batches\n",
        "class MyGenerator(Sequence):\n",
        "    def __init__(self, data, labels, batch_size):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return np.ceil(len(self.data) / self.batch_size).astype(int)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "# Define the hybrid model using MobileNetV3Small and InceptionV3\n",
        "def build_model(learning_rate):\n",
        "    input_shape = (224, 224, 3)\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Load pre-trained models\n",
        "    mobilenet_base = MobileNetV3Small(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    inception_base = InceptionV3(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "\n",
        "    # Set models as trainable\n",
        "    mobilenet_base.trainable = True\n",
        "    inception_base.trainable = True\n",
        "\n",
        "    # Extract and concatenate features\n",
        "    mobilenet_features = GlobalAveragePooling2D()(mobilenet_base.output)\n",
        "    inception_features = GlobalAveragePooling2D()(inception_base.output)\n",
        "    combined_features = Concatenate()([mobilenet_features, inception_features])\n",
        "\n",
        "    # Add classification layers\n",
        "    x = Dense(512, activation='relu')(combined_features)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    outputs = Dense(2, activation='sigmoid')(x)  # Adjust the number of classes if necessary\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',  # Adjust loss function based on your classification problem\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Genetic algorithm to optimize the learning rate\n",
        "def genetic_algorithm(train_generator, val_generator, population_size=10, generations=10, num_parents=4, mutation_rate=0.1):\n",
        "    population = np.random.uniform(low=1e-6, high=1e-2, size=population_size)\n",
        "    best_accuracy = 0\n",
        "    best_learning_rate = 0\n",
        "\n",
        "    for generation in range(generations):\n",
        "        fitness = []\n",
        "        for rate in population:\n",
        "            model = build_model(rate)\n",
        "            accuracy = model.evaluate(val_generator, verbose=0)[1]\n",
        "            fitness.append(accuracy)\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_learning_rate = rate\n",
        "\n",
        "        print(f\"Generation {generation}: Best Accuracy = {best_accuracy}, Best Learning Rate = {best_learning_rate}\")\n",
        "        parents_idx = np.random.choice(np.arange(len(fitness)), size=num_parents, replace=False, p=np.array(fitness) / np.sum(fitness))\n",
        "        parents = population[parents_idx]\n",
        "\n",
        "        # Creating next generation\n",
        "        next_population = []\n",
        "        for _ in range(int(population_size / 2)):\n",
        "            parent1, parent2 = np.random.choice(parents, 2, replace=False)\n",
        "            offspring1 = (parent1 + parent2) / 2\n",
        "            offspring2 = (parent1 + parent2) / 2\n",
        "            offspring1 = offspring1 * np.random.uniform(0.9, 1.1)\n",
        "            offspring2 = offspring2 * np.random.uniform(0.9, 1.1)\n",
        "            next_population.extend([offspring1, offspring2])\n",
        "\n",
        "        population = np.array(next_population)\n",
        "\n",
        "    return best_learning_rate\n",
        "\n",
        "# Example usage - Ensure your data is loaded and preprocessed into X_train, y_train, X_test, y_test\n",
        "train_generator = MyGenerator(X_train, y_train, batch_size=64)\n",
        "val_generator = MyGenerator(X_test, y_test, batch_size=64)\n",
        "best_learning_rate = genetic_algorithm(train_generator, val_generator)\n",
        "print(f\"Optimized Learning Rate: {best_learning_rate}\")\n"
      ],
      "metadata": {
        "id": "-HNv-zj6FI06",
        "outputId": "705406c1-2e7b-4b6d-f679-6fc46a7a6567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0: Best Accuracy = 0.559900164604187, Best Learning Rate = 0.009254262019058608\n",
            "Generation 1: Best Accuracy = 0.559900164604187, Best Learning Rate = 0.009254262019058608\n",
            "Generation 2: Best Accuracy = 0.559900164604187, Best Learning Rate = 0.009254262019058608\n",
            "Generation 3: Best Accuracy = 0.559900164604187, Best Learning Rate = 0.009254262019058608\n",
            "Generation 4: Best Accuracy = 0.559900164604187, Best Learning Rate = 0.009254262019058608\n",
            "Generation 5: Best Accuracy = 0.559900164604187, Best Learning Rate = 0.009254262019058608\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4e3629ec4a19>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mbest_learning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Optimized Learning Rate: {best_learning_rate}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-4e3629ec4a19>\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(train_generator, val_generator, population_size, generations, num_parents, mutation_rate)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m                         ):\n\u001b[1;32m   2295\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2297\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRID SEARCH FOR HYPERPARAMETER TUNING"
      ],
      "metadata": {
        "id": "HRIEaarLtAEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy-UyGE_Lfxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "23df0006-c760-4a65-a288-503ce5cc08ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:1273: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-358cc180fee9>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Evaluate on validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Create an iterator that yields batches for one epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             batches = [\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             batches = [\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ]\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             x = self.image_data_generator.apply_transform(\n\u001b[0m\u001b[1;32m    655\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0mimg_channel_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_axis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m         x = apply_affine_transform(\n\u001b[0m\u001b[1;32m   1414\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0mtransform_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m   1877\u001b[0m         \u001b[0mfinal_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m         channel_images = [\n\u001b[0m\u001b[1;32m   1880\u001b[0m             scipy.ndimage.interpolation.affine_transform(\n\u001b[1;32m   1881\u001b[0m                 \u001b[0mx_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m         channel_images = [\n\u001b[0;32m-> 1880\u001b[0;31m             scipy.ndimage.interpolation.affine_transform(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mx_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mfinal_affine_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/ndimage/_interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    626\u001b[0m                              mode, cval, npad, False)\n\u001b[1;32m    627\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0m\u001b[1;32m    629\u001b[0m                                       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                                       None)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, VGG19\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameter grid\n",
        "learning_rates = [1e-3, 1e-4]\n",
        "dense_1_units = [256, 512]\n",
        "dropout_1_rates = [0.2, 0.3]\n",
        "dense_2_units = [128, 256]\n",
        "dropout_2_rates = [0.2, 0.3]\n",
        "\n",
        "# Input shape\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Grid Search Loop\n",
        "best_model = None\n",
        "best_val_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "\n",
        "for lr, d1_units, d1_drop, d2_units, d2_drop in product(learning_rates, dense_1_units, dropout_1_rates, dense_2_units, dropout_2_rates):\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    vgg_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    resnet_base.trainable = True\n",
        "    vgg_base.trainable = True\n",
        "\n",
        "    resnet_features = GlobalAveragePooling2D()(resnet_base(inputs))\n",
        "    vgg_features = GlobalAveragePooling2D()(vgg_base(inputs))\n",
        "\n",
        "    combined_features = Concatenate()([resnet_features, vgg_features])\n",
        "\n",
        "    x = Dense(d1_units, activation='relu')(combined_features)\n",
        "    x = Dropout(d1_drop)(x)\n",
        "    x = Dense(d2_units, activation='relu')(x)\n",
        "    x = Dropout(d2_drop)(x)\n",
        "    outputs = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=60, verbose=0)\n",
        "\n",
        "    # Evaluate on validation data\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "    print(f\"Params: lr={lr}, d1_units={d1_units}, d1_drop={d1_drop}, d2_units={d2_units}, d2_drop={d2_drop}, val_acc={val_accuracy:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_model = model\n",
        "        best_params = {'learning_rate': lr, 'dense_1_units': d1_units, 'dropout_1_rate': d1_drop, 'dense_2_units': d2_units, 'dropout_2_rate': d2_drop}\n",
        "\n",
        "print(\"Best Validation Accuracy:\", best_val_accuracy)\n",
        "print(\"Best Hyperparameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENETIC ALGORITHM"
      ],
      "metadata": {
        "id": "0bcQWAdO1ILc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mugegu_dze-F",
        "outputId": "10c74137-7d1c-40ea-ac83-95ad89441ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n",
            "Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wivCSiFxLfxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b190adf-4a8b-411d-f7a3-2173662edff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, VGG19\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "import gc\n",
        "\n",
        "# Enable GPU memory growth to avoid allocating all memory upfront\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Pre-trained base models are loaded once to save computation\n",
        "input_shape = (224, 224, 3)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Define global base models\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "vgg_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "resnet_base.trainable = False  # Freeze ResNet50\n",
        "vgg_base.trainable = False  # Freeze VGG19\n",
        "\n",
        "# Fitness Function\n",
        "def evaluate(params):\n",
        "    \"\"\"Evaluate model accuracy for given hyperparameters.\"\"\"\n",
        "    # Unpack hyperparameters\n",
        "    lr, d1_units, d1_drop, d2_units, d2_drop = params\n",
        "\n",
        "    # Clear session and garbage collect to reduce memory leaks\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    # Feature extraction using pre-trained models\n",
        "    resnet_features = GlobalAveragePooling2D()(resnet_base(inputs))\n",
        "    vgg_features = GlobalAveragePooling2D()(vgg_base(inputs))\n",
        "    combined_features = Concatenate()([resnet_features, vgg_features])\n",
        "\n",
        "    # Classification head\n",
        "    x = Dense(d1_units, activation='relu')(combined_features)\n",
        "    x = Dropout(d1_drop)(x)\n",
        "    x = Dense(d2_units, activation='relu')(x)\n",
        "    x = Dropout(d2_drop)(x)\n",
        "    outputs = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=lr),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Add EarlyStopping callback to avoid overtraining\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model using your train_generator and validation set\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,  # Short epochs for quicker evaluation\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=0  # Suppress training output for clarity\n",
        "    )\n",
        "\n",
        "    # Return the best validation accuracy\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "    return val_accuracy,\n",
        "\n",
        "# Genetic Algorithm Setup\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_lr\", random.choice, [1e-3, 1e-4, 1e-5])\n",
        "toolbox.register(\"attr_d1_units\", random.choice, [256, 512, 1024])\n",
        "toolbox.register(\"attr_d1_drop\", random.uniform, 0.2, 0.5)\n",
        "toolbox.register(\"attr_d2_units\", random.choice, [128, 256, 512])\n",
        "toolbox.register(\"attr_d2_drop\", random.uniform, 0.2, 0.5)\n",
        "\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_lr, toolbox.attr_d1_units, toolbox.attr_d1_drop,\n",
        "                  toolbox.attr_d2_units, toolbox.attr_d2_drop), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "# Run Genetic Algorithm\n",
        "population = toolbox.population(n=10)\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, verbose=True)\n",
        "\n",
        "# Get the best individual and hyperparameters\n",
        "best_individual = tools.selBest(population, 1)[0]\n",
        "print(\"Best Hyperparameters:\", {\n",
        "    'learning_rate': best_individual[0],\n",
        "    'dense_1_units': best_individual[1],\n",
        "    'dropout_1_rate': best_individual[2],\n",
        "    'dense_2_units': best_individual[3],\n",
        "    'dropout_2_rate': best_individual[4]\n",
        "})\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}